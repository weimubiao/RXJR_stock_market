#下面的agent1是代理名称,对应有source,名称是s1,有一个sink,名称是k1,有一个channel,名称是c1.
agent1.sources = s1 s2
agent1.channels = c1
agent1.sinks = k1

#配置数据源source(用于接受服务器B的数据)
agent1.sources.s1.type = avro
agent1.sources.s1.bind= 0.0.0.0    
agent1.sources.s1.port= 44444    
agent1.sources.s1.channels= c1
agent1.sources.s1.batchSize=1000
agent1.sources.s1.batchTimeout=1000

agent1.sources.s2.type = exec
agent1.sources.s2.channels = c1
agent1.sources.s2.command = tail -F /usr/local/stock/stock.log
agent1.sources.s2.batchSize=10000
agent1.sources.s2.batchTimeout=1000

# 配置内存 channel
agent1.channels.c1.type = memory
agent1.channels.c1.capacity = 100000
agent1.channels.c1.transactionCapacity = 10000

# 配置 sinks(发送到文件)
#agent1.sinks.k1.channel = c1
#agent1.sinks.k1.type = file_roll
#agent1.sinks.k1.sink.directory = /tmp/flume
#默认值为30,即每30秒生成一个文件  
#为0时表示只有一个文件存放数据
#agent1.sinks.k1.sink.rollInterval  = 0

#设置Kafka接收器(发送到设置Kafka接收器)
agent1.sinks.k1.type= org.apache.flume.sink.kafka.KafkaSink
#设置Kafka的broker地址和端口号
agent1.sinks.k1.brokerList=192.168.xx.100:9092,192.168.xx.101:9092
#设置Kafka的Topic
agent1.sinks.k1.topic=stock
agent1.sinks.k1.batchSize = 1000
#设置为0时延时最低，数据的持久化保证最弱
agent1.sinks.k1.requiredAcks=0
agent1.sinks.k1.channel=c1



